# ğŸ¤– AI-Powered Research Paper Assistant

A cutting-edge tool that helps users intelligently **search**, **summarize**, and **interact** with academic research papers using **LLMs**, **semantic search**, **Arxiv integration**, and a clean **Streamlit UI**.

---

## ğŸš€ Overview

The **Research Paper Assistant** makes academic exploration easier by combining advanced Natural Language Processing (NLP) techniques with an intuitive interface. It supports:

* ğŸ” Natural language paper lookup via Arxiv
* ğŸ§  Summarization, direct question answering, and metric extraction using LLaMA-3 from Groq
* âš¡ Semantic search using FAISS and sentence embeddings
* ğŸ“ Metadata management for precise source tracking
* ğŸŒ A Streamlit web app for seamless user interaction

---

## ğŸ§  Why This Project Stands Out

ğŸ‘Œ **Real-Time Semantic Search**: Uses FAISS and Sentence Transformers for fast, accurate retrieval of relevant content from papers.

ğŸ•Š **High-Performance LLM (Groq + LLaMA-3)**: Ultra-fast responses with contextual understanding for summarization and Q\&A.

ğŸ” **Arxiv Search API**: Allows keyword-based or descriptive paper search directly from the app.

ğŸ— **Metadata Management**: Links every result with its source (chunk, position), ensuring transparency and explainability.

ğŸ“… **Modular Architecture**: Clean separation between UI, retrieval logic, LLM agent, and Arxiv integration.

ğŸ“Š **Extendable**: Future integration with PDF upload, citation extraction, or image caption analysis (BLIP) is possible.

---

## ğŸ› ï¸ Features

| Feature              | Description                                                             |
| -------------------- | ----------------------------------------------------------------------- |
| ğŸ” Arxiv Search      | Find papers using natural language queries like "transformer-based OCR" |
| ğŸ§¬ Vector Retrieval  | Retrieve context using FAISS + BAAI sentence embeddings                 |
| ğŸ“ Summarization     | Get concise and clear summaries using LLM                               |
| â“ Q\&A               | Ask questions and get context-aware answers                             |
| ğŸ“Š Metric Extraction | Extract numbers, statistics, or performance metrics from text           |
| ğŸ§  LLM-Powered       | Groq-hosted LLaMA-3 70B for speed and quality                           |
| ğŸ’¡ Streamlit UI      | Easy-to-use and responsive frontend                                     |

---

## ğŸ“ Project Structure

```
research-paper-assistant/
â”œâ”€â”€ streamlit_ui/
â”‚   â””â”€â”€ ui.py                  # Streamlit frontend logic
â”œâ”€â”€ vector_store/
â”‚   â”œâ”€â”€ faiss_store.index      # FAISS index file for embeddings
â”‚   â””â”€â”€ metadata.json          # Metadata for each text chunk
â”œâ”€â”€ retriever.py               # Handles vector-based retrieval
â”œâ”€â”€ llm_agent.py               # Prompt building and LLM invocation via Groq
â”œâ”€â”€ arxiv_search.py            # Arxiv search integration
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # Project documentation
```

---

## âš™ï¸ Installation & Setup

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/research-paper-assistant.git
cd research-paper-assistant
```

### 2. Install Requirements

```bash
pip install -r requirements.txt
```

Make sure you delete the faiss_idex , metadata.js and report.pdfs before running the server

### 3. Set API Key (Groq)

In `llm_agent.py`, replace your Groq API key:

```python
ChatGroq(groq_api_key="your_groq_api_key", ...)
```

You can also add it in an `.env` file and use `python-dotenv` to load it securely.

### 4. Run the App

```bash
streamlit run streamlit_ui/ui.py
```

---

## ğŸ§º Example Prompts

* â€œSummarize the methodology of this paper.â€
* â€œWhat are the main findings from the latest transformer OCR research?â€
* â€œExtract all numerical results from this document.â€
* â€œFind a paper about multi-modal diffusion in vision-language models.â€

---

## ğŸ”Œ Arxiv Integration Example

Search a paper using:

> "Find a paper on transformer-based OCR systems"

The app will:

1. Query Arxiv API.
2. Return top result: title, authors, abstract.
3. Provide PDF and paper links.

---

## ğŸ“‚ Technologies Used

* **Groq LLaMA-3 70B** â€“ lightning-fast LLM inference
* **FAISS** â€“ similarity search across paper chunks
* **Sentence Transformers (BAAI/bge-small-en-v1.5)** â€“ embedding text
* **Arxiv API** â€“ academic paper search
* **Streamlit** â€“ frontend UI
* **Python** â€“ core backend and logic

---

## ğŸ“Œ Why We Use Metadata?

Metadata stores the source chunk for every embedding, so when a vector is retrieved from FAISS, we can trace it back to the original content and paper. This improves:

* âœ… **Explainability** of answers
* âœ… **Traceability** of source text
* âœ… **Modular chunk-based search**

## ğŸ‘ Contributing

Contributions are welcome! Please open issues for bugs or submit a PR for improvements.

---

## ğŸ“¬ Contact

**Author**: Arnav Singh
Email: toshu129@gail.com
GitHub:https://github.com/toshu134

---

## ğŸŒŸ If You Like This Project...

Give it a â­ on GitHub and share it with friends in research or academia!
